{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TextClassificationPipeline, AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ElKulako/cryptobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "posts = []\n",
    "posts.append(\"Bitcoin is going Up.  Buy, BUy, BUy\")\n",
    "posts.append(\"Bitcoin #BTC is Down. Bad\")\n",
    "preds = pipe(posts)\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bitcoin #BTC is going Up.  it is great\"\n",
    "sentence1 = \"Bitcoin #BTC is Down. Bad\"\n",
    "labels =[\"Bearish\", \"Neutral\", \"Bullish\"]\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus([sentence, sentence1],\n",
    "                                    return_tensors='pt', max_length=256,\n",
    "                                    truncation=True, padding='max_length'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = inputs['input_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "input_ids.shape, attention_mask.shape\n",
    "\n",
    "print(attention_mask[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorch_to_TorchScript(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PyTorch_to_TorchScript, self).__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name,  num_labels = 3)\n",
    "    def forward(self, data, attention_mask=None):\n",
    "        return self.model(data, attention_mask)[0]\n",
    "# after trace it will save the model in cwd\n",
    "pt_model = PyTorch_to_TorchScript().eval()\n",
    "\n",
    "# remove_attributes = []\n",
    "# for key, value in vars(pt_model).items():\n",
    "#     if value is None:\n",
    "#         print(f'remove_attributes {key}')\n",
    "#         remove_attributes.append(key)\n",
    "\n",
    "# for key in remove_attributes:\n",
    "#     delattr(pt_model, key)\n",
    "\n",
    "traced_script_module = torch.jit.trace(pt_model, (input_ids, attention_mask), strict=False)\n",
    "traced_script_module.save(\"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"\"\"\n",
    "name: \"bitcoin-model\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    " {\n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ 256 ]\n",
    "  } ,\n",
    "{\n",
    "    name: \"input__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [ 256 ]\n",
    "  }\n",
    "]\n",
    "output {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 3 ]\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "with open('./config.pbtxt', 'w') as file:\n",
    "    file.write(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('capstone-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a2301b27a96f16339357710498ba8c33f970a6ee54734da470ddf5cd6d173d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
